{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Y7G_X51tEKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Libraries import - Yeh sab tools hain jo hum analysis ke liye use karenge  \n",
        "\n",
        "import pandas as pd\n",
        "  # Data ko table ki form mein manage karne ke liye (Excel jaisa)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "  # Graphs banane ke liye\n",
        "\n",
        "import seaborn as sns\n",
        "  # Matlab ke stylish graphs banane ke liye (seaborn matplotlib ka upgraded version hai)\n",
        "\n",
        "\n",
        "\n",
        "# 2) Titanic dataset load - Internet se direct data utha rahe hain\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
        "# df = dataframe (ek type ka digital table jisme sab data store hoga)\n",
        "# pd.read_csv() = pandas ka function jo CSV file ko load karta hai\n",
        "# Yeh link ek public dataset ka hai jo Titanic ki information rakhta hai\n",
        "\n",
        "\n",
        "\n",
        "# 3) Data ka overview - Dataset ki basic jankari lene ke liye\n",
        "\n",
        "print(df.info())  \n",
        "# df.info() = batata hai kitne columns hain, unke names, aur kitni values missing hain\n",
        "# print() = console pe output dikhane ke liye\n",
        "\n",
        "display(df.head())  \n",
        "# df.head() = dataframe ke first 5 rows dikhata hai"
      ],
      "metadata": {
        "id": "Hzdmeyn5t9Bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task¬†1 Insights\n",
        "- **Survival Rate**: ~38% passengers survived.\n",
        "- **First Class**: Greatest survival rate.\n",
        "- **Age**: Majority between 20‚Äì40 years.\n",
        "- **Correlations**: Fare strongly linked to passenger class.\n"
      ],
      "metadata": {
        "id": "0dNK9sje_wat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚Äî Task 2: Text Sentiment Analysis using NLTK movie_reviews corpus\n",
        "\n",
        "import nltk\n",
        "# Pehle required corpora download karo (sirf pehli baar run karna hai)\n",
        "nltk.download('punkt')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1) Data load & labels prepare\n",
        "docs = [(movie_reviews.raw(fileid), category)\n",
        "        for category in movie_reviews.categories()\n",
        "        for fileid in movie_reviews.fileids(category)]\n",
        "texts = [text for text, label in docs]\n",
        "labels = [1 if label=='pos' else 0 for text, label in docs]\n",
        "\n",
        "# 2) Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3) TF-IDF vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tf = tfidf.fit_transform(X_train)\n",
        "X_test_tf  = tfidf.transform(X_test)\n",
        "\n",
        "# 4) Model training\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train_tf, y_train)\n",
        "\n",
        "# 5) Prediction & Evaluation\n",
        "y_pred = model.predict(X_test_tf)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "id": "yXSplpSMBtJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# üè† HOUSE PRICE PREDICTION (BOSTON HOUSING)\n",
        "# ==============================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# üö® Note: load_boston() is deprecated in newer sklearn versions\n",
        "# We'll use the proper alternative dataset loading method\n",
        "try:\n",
        "    from sklearn.datasets import fetch_openml\n",
        "    boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
        "    X_df = boston.data\n",
        "    y = boston.target\n",
        "except:\n",
        "    # Fallback for older sklearn versions\n",
        "    from sklearn.datasets import load_boston\n",
        "    boston = load_boston()\n",
        "    X_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "    y = boston.target\n",
        "\n",
        "print(\"\\nüîç Dataset Preview:\")\n",
        "print(X_df.head())\n",
        "\n",
        "# ==============================================\n",
        "# üìä 1. LINEAR REGRESSION FROM SCRATCH\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nüßÆ Linear Regression from Scratch...\")\n",
        "\n",
        "try:\n",
        "    # Add intercept term (column of 1s)\n",
        "    X = np.hstack([np.ones((X_df.shape[0], 1)), X_df.values])\n",
        "\n",
        "    # Normal equation: Œ∏ = (X·µÄX)‚Åª¬πX·µÄy\n",
        "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_lin = X.dot(theta)\n",
        "\n",
        "    # Calculate metrics\n",
        "    rmse_lin = np.sqrt(mean_squared_error(y, y_pred_lin))\n",
        "    r2_lin = r2_score(y, y_pred_lin)\n",
        "    print(f\"‚úÖ Linear Regression ‚Üí RMSE: {rmse_lin:.3f}, R¬≤: {r2_lin:.3f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Linear Regression Error: {e}\")\n",
        "\n",
        "# ==============================================\n",
        "# üå≥ 2. RANDOM FOREST (FOR COMPARISON)\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nüå≥ Training Random Forest Model...\")\n",
        "\n",
        "try:\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "    rf = RandomForestRegressor(\n",
        "        n_estimators=100,  # 100 decision trees\n",
        "        random_state=1,     # Reproducible results\n",
        "        n_jobs=-1          # Use all CPU cores\n",
        "    )\n",
        "    rf.fit(X_df, y)\n",
        "    y_pred_rf = rf.predict(X_df)\n",
        "\n",
        "    rmse_rf = np.sqrt(mean_squared_error(y, y_pred_rf))\n",
        "    r2_rf = r2_score(y, y_pred_rf)\n",
        "    print(f\"‚úÖ Random Forest ‚Üí RMSE: {rmse_rf:.3f}, R¬≤: {r2_rf:.3f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Random Forest Error: {e}\")\n",
        "\n",
        "# ==============================================\n",
        "# üöÄ 3. XGBOOST (IF AVAILABLE)\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nüöÄ Attempting XGBoost...\")\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "\n",
        "    xgb = XGBRegressor(\n",
        "        n_estimators=100,\n",
        "        random_state=1,\n",
        "        eval_metric='rmse',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    xgb.fit(X_df, y)\n",
        "    y_pred_xgb = xgb.predict(X_df)\n",
        "\n",
        "    rmse_xgb = np.sqrt(mean_squared_error(y, y_pred_xgb))\n",
        "    r2_xgb = r2_score(y, y_pred_xgb)\n",
        "    print(f\"‚úÖ XGBoost ‚Üí RMSE: {rmse_xgb:.3f}, R¬≤: {r2_xgb:.3f}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è XGBoost not installed. To install: pip install xgboost\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå XGBoost Error: {e}\")\n",
        "\n",
        "# ==============================================\n",
        "# üìä FINAL COMPARISON\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nüèÜ Model Comparison:\")\n",
        "try:\n",
        "    results = pd.DataFrame({\n",
        "        'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
        "        'RMSE': [rmse_lin, rmse_rf, rmse_xgb if 'rmse_xgb' in locals() else np.nan],\n",
        "        'R¬≤': [r2_lin, r2_rf, r2_xgb if 'r2_xgb' in locals() else np.nan]\n",
        "    })\n",
        "    print(results.dropna())\n",
        "except:\n",
        "    print(\"Could not generate comparison table\")\n",
        "\n",
        "print(\"\\nüéâ Analysis Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuixsZ0Fb_03",
        "outputId": "60525c7d-372f-48b1-b8a7-1640cd11ba70"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Dataset Preview:\n",
            "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  PTRATIO  \\\n",
            "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0     15.3   \n",
            "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0     17.8   \n",
            "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0     17.8   \n",
            "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0     18.7   \n",
            "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0     18.7   \n",
            "\n",
            "        B  LSTAT  \n",
            "0  396.90   4.98  \n",
            "1  396.90   9.14  \n",
            "2  392.83   4.03  \n",
            "3  394.63   2.94  \n",
            "4  396.90   5.33  \n",
            "\n",
            "üßÆ Linear Regression from Scratch...\n",
            "‚ùå Linear Regression Error: can't multiply sequence by non-int of type 'float'\n",
            "\n",
            "üå≥ Training Random Forest Model...\n",
            "‚úÖ Random Forest ‚Üí RMSE: 1.199, R¬≤: 0.983\n",
            "\n",
            "üöÄ Attempting XGBoost...\n",
            "‚ùå XGBoost Error: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:CHAS: category, RAD: category\n",
            "\n",
            "üèÜ Model Comparison:\n",
            "Could not generate comparison table\n",
            "\n",
            "üéâ Analysis Complete!\n"
          ]
        }
      ]
    }
  ]
}